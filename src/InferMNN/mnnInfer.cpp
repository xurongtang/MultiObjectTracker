// MNNInfer.cpp (ä¿®å¤ç‰ˆ)
#include "mnnInfer.h"
#include <iostream>
#include <vector>
#include <opencv2/opencv.hpp>

MNNInfer::MNNInfer(std::string modelPath,float mean_[3],float std_[3])
    : m_modelPath(modelPath) {
        for(int i = 0; i < 3; i++)
        {
            mnn_mean[i] = mean_[i];
            mnn_std[i] = std_[i];
        }
    }

MNNInfer::~MNNInfer() {
    if (m_session) {
        m_net->releaseSession(m_session);
    }
}

int MNNInfer::loadModel() {
    m_net = std::shared_ptr<MNN::Interpreter>(MNN::Interpreter::createFromFile(m_modelPath.c_str()));
    if (!m_net) {
        std::cerr << "âŒ Failed to load MNN model: " << m_modelPath << std::endl;
        return -1;
    }

    MNN::ScheduleConfig config;
    config.type = MNN_FORWARD_CPU;
    MNN::BackendConfig backendConfig;
    backendConfig.precision = MNN::BackendConfig::Precision_High;
    config.backendConfig = &backendConfig;

    m_session = m_net->createSession(config);
    if (!m_session) {
        std::cerr << "âŒ Failed to create MNN session." << std::endl;
        return -1;
    }

    // è·å–è¾“å…¥å¼ é‡
    auto inputTensors = m_net->getSessionInputAll(m_session);
    if (inputTensors.empty()) {
        std::cerr << "âŒ No input tensor found!" << std::endl;
        return -1;
    }
    std::string inputName = inputTensors.begin()->first;
    m_inputTensor = inputTensors.begin()->second;
    
    if (!m_inputTensor) {
        std::cerr << "âŒ Failed to get input tensor." << std::endl;
        return -1;
    }

    // æ‰“å°è¾“å…¥ä¿¡æ¯
    auto shape = m_inputTensor->shape();
    std::cout << "âœ… Model loaded. Input shape (NCHW): ";
    for (size_t i = 0; i < shape.size(); ++i) {
        std::cout << shape[i] << " ";
    }
    std::cout << std::endl;

    return 0;
}

int MNNInfer::runInference(std::vector<cv::Mat> &inputs, std::vector<std::vector<float>> &outputs) {
    if (!m_session || !m_inputTensor) {
        std::cerr << "âŒ Model not loaded!" << std::endl;
        return -1;
    }
    if (inputs.empty()) {
        std::cerr << "âŒ Input images is empty!" << std::endl;
        return -1;
    }

    auto shape = m_inputTensor->shape();
    int batch = shape[0];
    int channel = shape[1];
    int height = shape[2];
    int width = shape[3];

    // std::cout << "ğŸ“Š Input image size: " << inputs[0].cols << " x " << inputs[0].rows << std::endl;
    // std::cout << "ğŸ“Š Model expects: " << width << "x" << height << " (WxH)" << std::endl;

    if (static_cast<int>(inputs.size()) > batch) {
        std::cerr << "âŒ Input batch size exceeds model capacity!" << std::endl;
        return -1;
    }

    // âœ… å…³é”®ä¿®å¤ï¼šä½¿ç”¨ CAFFE (NCHW) æ ¼å¼
    MNN::Tensor inputUser(m_inputTensor, MNN::Tensor::CAFFE); // NCHW
    auto inputPtr = inputUser.host<float>();

    // é…ç½®é¢„å¤„ç†ï¼ˆå½’ä¸€åŒ–åˆ° [0,1]ï¼ŒBGRâ†’RGBï¼‰
    MNN::CV::ImageProcess::Config config;
    config.filterType = MNN::CV::BILINEAR;
    config.sourceFormat = MNN::CV::BGR;   // OpenCV é»˜è®¤ BGR
    config.destFormat = MNN::CV::RGB;     // æ¨¡å‹éœ€è¦ RGB

    for (int i = 0; i < 3; ++i) {
        config.mean[i]   = mnn_mean[i];
        config.normal[i] = 1.0f / (mnn_std[i] * 255.0f);
    }
    
    auto process = std::shared_ptr<MNN::CV::ImageProcess>(MNN::CV::ImageProcess::create(config));

    for (size_t i = 0; i < inputs.size(); ++i) {
        cv::Mat& img = inputs[i];
        if (img.empty()) continue;

        cv::Mat resized;
        cv::resize(img, resized, cv::Size(width, height)); // æ³¨æ„ï¼šSize(width, height)

        // âœ… å…³é”®ï¼šä½¿ç”¨ CAFFE æ ¼å¼ï¼Œconvert ä¼šè‡ªåŠ¨è¾“å‡º NCHW
        float* batchPtr = inputPtr + i * channel * height * width;
        process->convert(
            resized.data,    // BGR input
            width, height,   // è¾“å…¥å®½é«˜
            width * 3,       // è¾“å…¥ stride (BGR)
            batchPtr,        // è¾“å‡ºæŒ‡é’ˆ (NCHW)
            width, height    // è¾“å‡ºå°ºå¯¸
        );
    }

    m_inputTensor->copyFromHostTensor(&inputUser);
    m_net->runSession(m_session);

    // è·å–å¹¶æ‰“å°è¾“å‡º
    outputs.clear();
    output_shapes.clear();
    
    auto outputNames = m_net->getSessionOutputAll(m_session);
    // std::cout << "ğŸ“¤ Number of output tensors: " << outputNames.size() << std::endl;

    for (const auto& pair : outputNames) {
        const std::string& name = pair.first;
        auto outputTensor = m_net->getSessionOutput(m_session, name.c_str());
        
        // æ‰“å°è¾“å‡ºå½¢çŠ¶
        auto outShape = outputTensor->shape();
        output_shapes.push_back({name, outShape});
        size_t total = 1;
        // std::cout << "--- Output[" << name << "] ---\nShape: ";
        for (auto s : outShape) {
            // std::cout << s << " ";
            total *= s;
        }
        // std::cout << "\nTotal elements: " << total << std::endl;

        // æ‹·è´åˆ° host
        MNN::Tensor outputUser(outputTensor, MNN::Tensor::CAFFE);
        outputTensor->copyToHostTensor(&outputUser);

        std::vector<float> outVec(outputUser.host<float>(), outputUser.host<float>() + total);
        outputs.push_back(std::move(outVec));

        // æ‰“å°å‰10ä¸ªå€¼
        // std::cout << "First 10 values: ";
        // for (int j = 0; j < std::min(10, (int)outVec.size()); ++j) {
        //     std::cout << outVec[j] << " ";
        // }
        // std::cout << "\n" << std::endl;
    }

    return 0;
}